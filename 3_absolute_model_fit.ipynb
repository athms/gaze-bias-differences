{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from bambi import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glam.plots import plot_correlation\n",
    "\n",
    "from analysis_functions import compute_gaze_influence_score, compute_mean_rt, compute_p_choose_best, make_sure_path_exists\n",
    "from analysis_functions import q1, q3, iqr, std, se, add_best_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(52) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Absolute model fit (out of sample prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load *observed* data (test set) GLAM out of sample *predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('data/data_aggregate.csv')\n",
    "even = all_data[(all_data['trial'] % 2) == 0].reset_index(drop=True)\n",
    "odd = all_data[(all_data['trial'] % 2) == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>rt</th>\n",
       "      <th>choice</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>item_value_2</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "      <th>gaze_2</th>\n",
       "      <th>n_items</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3808.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663725</td>\n",
       "      <td>0.336275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.673317</td>\n",
       "      <td>0.326683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425759</td>\n",
       "      <td>0.574241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.439809</td>\n",
       "      <td>0.560191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial      rt  choice  item_value_0  item_value_1  item_value_2  \\\n",
       "0        0      0  3808.0     0.0           4.0           2.0           NaN   \n",
       "1        0      2  1121.0     1.0           5.0          10.0           NaN   \n",
       "2        0      4  1655.0     1.0           6.0           7.0           NaN   \n",
       "3        0      6  2002.0     0.0           3.0           3.0           NaN   \n",
       "4        0      8  1065.0     1.0           5.0           8.0           NaN   \n",
       "\n",
       "     gaze_0    gaze_1  gaze_2  n_items       dataset  \n",
       "0  0.663725  0.336275     NaN        2  krajbich2010  \n",
       "1  0.673317  0.326683     NaN        2  krajbich2010  \n",
       "2  0.425759  0.574241     NaN        2  krajbich2010  \n",
       "3  0.439809  0.560191     NaN        2  krajbich2010  \n",
       "4  0.447368  0.552632     NaN        2  krajbich2010  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>rt</th>\n",
       "      <th>choice</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>item_value_2</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "      <th>gaze_2</th>\n",
       "      <th>n_items</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464375</td>\n",
       "      <td>0.535625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524205</td>\n",
       "      <td>0.475795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.429714</td>\n",
       "      <td>0.570286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  trial      rt  choice  item_value_0  item_value_1  item_value_2  \\\n",
       "0        0      1  1913.0     0.0           3.0           2.0           NaN   \n",
       "1        0      3  2051.0     1.0           6.0           6.0           NaN   \n",
       "2        0      5  2504.0     0.0           6.0           2.0           NaN   \n",
       "3        0      7  1426.0     0.0           6.0           5.0           NaN   \n",
       "4        0      9  1209.0     0.0           6.0           8.0           NaN   \n",
       "\n",
       "     gaze_0    gaze_1  gaze_2  n_items       dataset  \n",
       "0  0.466578  0.533422     NaN        2  krajbich2010  \n",
       "1  0.464375  0.535625     NaN        2  krajbich2010  \n",
       "2  0.524205  0.475795     NaN        2  krajbich2010  \n",
       "3  1.000000  0.000000     NaN        2  krajbich2010  \n",
       "4  0.429714  0.570286     NaN        2  krajbich2010  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "prediction_multiplicative_list = []\n",
    "prediction_nobias_list = []\n",
    "\n",
    "# join prediction dataframes\n",
    "for subject in odd['subject'].unique():\n",
    "    subject_pred_multiplicative = pd.read_csv(os.path.join('results', 'predictions', 'out_of_sample', 'multiplicative', 'prediction_{}_multiplicative_oos.csv'.format(subject)), index_col=0)\n",
    "    subject_pred_nobias = pd.read_csv(os.path.join('results', 'predictions', 'out_of_sample', 'nobias', 'prediction_{}_nobias_oos.csv'.format(subject)), index_col=0)\n",
    "    subject_pred_multiplicative['subject'] = subject\n",
    "    subject_pred_nobias['subject'] = subject\n",
    "    \n",
    "    prediction_multiplicative_list.append(subject_pred_multiplicative)\n",
    "    prediction_nobias_list.append(subject_pred_nobias)\n",
    "\n",
    "prediction_multiplicative = pd.concat(prediction_multiplicative_list)\n",
    "prediction_nobias = pd.concat(prediction_nobias_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard trials with negative predicted RT\n",
    "prediction_multiplicative = prediction_multiplicative[prediction_multiplicative['rt'] > 0].copy()\n",
    "prediction_nobias = prediction_nobias[prediction_nobias['rt'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>dataset</th>\n",
       "      <th>gamma</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "      <th>gaze_2</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>item_value_2</th>\n",
       "      <th>n_items</th>\n",
       "      <th>repeat</th>\n",
       "      <th>rt</th>\n",
       "      <th>s</th>\n",
       "      <th>subject</th>\n",
       "      <th>t0</th>\n",
       "      <th>tau</th>\n",
       "      <th>trial</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3079.0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.466578</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   choice       dataset  gamma    gaze_0    gaze_1  gaze_2  item_value_0  \\\n",
       "0     1.0  krajbich2010   0.65  0.466578  0.533422     NaN           3.0   \n",
       "1     0.0  krajbich2010   0.65  0.466578  0.533422     NaN           3.0   \n",
       "2     0.0  krajbich2010   0.65  0.466578  0.533422     NaN           3.0   \n",
       "3     0.0  krajbich2010   0.65  0.466578  0.533422     NaN           3.0   \n",
       "4     0.0  krajbich2010   0.65  0.466578  0.533422     NaN           3.0   \n",
       "\n",
       "   item_value_1  item_value_2  n_items  repeat      rt         s  subject  \\\n",
       "0           2.0           NaN      2.0     0.0  1247.0  0.008368        0   \n",
       "1           2.0           NaN      2.0     1.0  3079.0  0.008368        0   \n",
       "2           2.0           NaN      2.0     2.0  2398.0  0.008368        0   \n",
       "3           2.0           NaN      2.0     3.0   960.0  0.008368        0   \n",
       "4           2.0           NaN      2.0     4.0  1515.0  0.008368        0   \n",
       "\n",
       "    t0   tau  trial         v  \n",
       "0  0.0  0.44    1.0  0.000098  \n",
       "1  0.0  0.44    1.0  0.000098  \n",
       "2  0.0  0.44    1.0  0.000098  \n",
       "3  0.0  0.44    1.0  0.000098  \n",
       "4  0.0  0.44    1.0  0.000098  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_multiplicative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>dataset</th>\n",
       "      <th>gamma</th>\n",
       "      <th>gaze_0</th>\n",
       "      <th>gaze_1</th>\n",
       "      <th>gaze_2</th>\n",
       "      <th>item_value_0</th>\n",
       "      <th>item_value_1</th>\n",
       "      <th>item_value_2</th>\n",
       "      <th>n_items</th>\n",
       "      <th>repeat</th>\n",
       "      <th>rt</th>\n",
       "      <th>s</th>\n",
       "      <th>subject</th>\n",
       "      <th>t0</th>\n",
       "      <th>tau</th>\n",
       "      <th>trial</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32645</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tavares2017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32646</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tavares2017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32647</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tavares2017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32648</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tavares2017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32649</th>\n",
       "      <td>1.0</td>\n",
       "      <td>tavares2017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.299389</td>\n",
       "      <td>0.700611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1305.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       choice      dataset  gamma    gaze_0    gaze_1  gaze_2  item_value_0  \\\n",
       "32645     1.0  tavares2017   0.01  0.299389  0.700611     NaN           4.0   \n",
       "32646     1.0  tavares2017   0.01  0.299389  0.700611     NaN           4.0   \n",
       "32647     1.0  tavares2017   0.01  0.299389  0.700611     NaN           4.0   \n",
       "32648     1.0  tavares2017   0.01  0.299389  0.700611     NaN           4.0   \n",
       "32649     1.0  tavares2017   0.01  0.299389  0.700611     NaN           4.0   \n",
       "\n",
       "       item_value_1  item_value_2  n_items  repeat      rt         s  subject  \\\n",
       "32645           7.0           NaN      2.0    45.0  3369.0  0.012259      117   \n",
       "32646           7.0           NaN      2.0    46.0   837.0  0.012259      117   \n",
       "32647           7.0           NaN      2.0    47.0  1461.0  0.012259      117   \n",
       "32648           7.0           NaN      2.0    48.0  1099.0  0.012259      117   \n",
       "32649           7.0           NaN      2.0    49.0  1151.0  0.012259      117   \n",
       "\n",
       "        t0   tau   trial       v  \n",
       "32645  0.0  0.25  1305.0  0.0001  \n",
       "32646  0.0  0.25  1305.0  0.0001  \n",
       "32647  0.0  0.25  1305.0  0.0001  \n",
       "32648  0.0  0.25  1305.0  0.0001  \n",
       "32649  0.0  0.25  1305.0  0.0001  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_multiplicative.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute behavioral indices for observed data and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_subject_level(data, n_items):\n",
    "    \"\"\"\n",
    "    Aggregates a single dataset to subject level\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # add best chosen variable\n",
    "    data = add_best_chosen(data)\n",
    "    \n",
    "    # Summarize variables\n",
    "    subject_summary = data.groupby('subject').agg({'rt': ['mean', std, 'min', 'max', se, q1, q3, iqr],\n",
    "                                                   'best_chosen': 'mean'})\n",
    "    # Influence of gaze on P(choice | value)\n",
    "    subject_summary['gaze_influence'] = compute_gaze_influence_score(data, n_items=n_items)\n",
    "    \n",
    "    subject_summary['dataset'] = data.groupby('subject')['dataset'].head(1).values\n",
    "    \n",
    "    return subject_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_summary_list = []\n",
    "pred_multiplicative_summary_list = []\n",
    "pred_nobias_summary_list = []\n",
    "\n",
    "for di, dataset in enumerate(odd['dataset'].unique()):\n",
    "    odd_di = odd[odd['dataset'] == dataset].copy()\n",
    "    n_items = odd_di['n_items'].unique()[0]\n",
    "    \n",
    "    odd_summary_di = aggregate_subject_level(odd_di, n_items=n_items)\n",
    "    \n",
    "    prediction_multiplicative_di = prediction_multiplicative[prediction_multiplicative['dataset'] == dataset].copy()\n",
    "    prediction_nobias_di = prediction_nobias[prediction_nobias['dataset'] == dataset].copy()\n",
    "    \n",
    "    pred_multiplicative_summary_di = aggregate_subject_level(prediction_multiplicative_di, n_items=n_items)\n",
    "    pred_nobias_summary_di = aggregate_subject_level(prediction_nobias_di, n_items=n_items)\n",
    "    \n",
    "    \n",
    "    odd_summary_list.append(odd_summary_di)\n",
    "    pred_multiplicative_summary_list.append(pred_multiplicative_summary_di)\n",
    "    pred_nobias_summary_list.append(pred_nobias_summary_di)\n",
    "    \n",
    "odd_summary = pd.concat(odd_summary_list)\n",
    "pred_multiplicative_summary = pd.concat(pred_multiplicative_summary_list)\n",
    "pred_nobias_summary = pd.concat(pred_nobias_summary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_multiplicative_summary.to_csv(os.path.join('results', 'predictions', 'out_of_sample', 'descriptives',\n",
    "                                                'subject_summary_multiplicative_oos.csv'))\n",
    "pred_nobias_summary.to_csv(os.path.join('results', 'predictions', 'out_of_sample', 'descriptives',\n",
    "                                        'subject_summary_nobias_oos.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">rt</th>\n",
       "      <th>best_chosen</th>\n",
       "      <th>gaze_influence</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>se</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>iqr</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483.665778</td>\n",
       "      <td>535.686925</td>\n",
       "      <td>471.0</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>11.295782</td>\n",
       "      <td>1117.25</td>\n",
       "      <td>1733.00</td>\n",
       "      <td>615.75</td>\n",
       "      <td>0.890222</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1502.737959</td>\n",
       "      <td>642.897107</td>\n",
       "      <td>423.0</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>12.991134</td>\n",
       "      <td>1062.25</td>\n",
       "      <td>1790.75</td>\n",
       "      <td>728.50</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.047497</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4427.150800</td>\n",
       "      <td>2895.781847</td>\n",
       "      <td>664.0</td>\n",
       "      <td>28717.0</td>\n",
       "      <td>57.927224</td>\n",
       "      <td>2411.75</td>\n",
       "      <td>5542.50</td>\n",
       "      <td>3130.75</td>\n",
       "      <td>0.846400</td>\n",
       "      <td>0.015188</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1921.084545</td>\n",
       "      <td>504.680828</td>\n",
       "      <td>838.0</td>\n",
       "      <td>4738.0</td>\n",
       "      <td>10.762278</td>\n",
       "      <td>1617.75</td>\n",
       "      <td>2145.00</td>\n",
       "      <td>527.25</td>\n",
       "      <td>0.688636</td>\n",
       "      <td>-0.009199</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1740.098400</td>\n",
       "      <td>794.662275</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5851.0</td>\n",
       "      <td>15.896425</td>\n",
       "      <td>1198.00</td>\n",
       "      <td>2084.00</td>\n",
       "      <td>886.00</td>\n",
       "      <td>0.840800</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rt                                                   \\\n",
       "                mean          std    min      max         se       q1   \n",
       "subject                                                                 \n",
       "0        1483.665778   535.686925  471.0   4115.0  11.295782  1117.25   \n",
       "1        1502.737959   642.897107  423.0   4639.0  12.991134  1062.25   \n",
       "2        4427.150800  2895.781847  664.0  28717.0  57.927224  2411.75   \n",
       "3        1921.084545   504.680828  838.0   4738.0  10.762278  1617.75   \n",
       "4        1740.098400   794.662275  500.0   5851.0  15.896425  1198.00   \n",
       "\n",
       "                          best_chosen gaze_influence       dataset  \n",
       "              q3      iqr        mean                               \n",
       "subject                                                             \n",
       "0        1733.00   615.75    0.890222      -0.002591  krajbich2010  \n",
       "1        1790.75   728.50    0.780000       0.047497  krajbich2010  \n",
       "2        5542.50  3130.75    0.846400       0.015188  krajbich2010  \n",
       "3        2145.00   527.25    0.688636      -0.009199  krajbich2010  \n",
       "4        2084.00   886.00    0.840800      -0.009003  krajbich2010  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_nobias_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">rt</th>\n",
       "      <th>best_chosen</th>\n",
       "      <th>gaze_influence</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>se</th>\n",
       "      <th>q1</th>\n",
       "      <th>q3</th>\n",
       "      <th>iqr</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2189.337197</td>\n",
       "      <td>2153.038110</td>\n",
       "      <td>286.0</td>\n",
       "      <td>17284.0</td>\n",
       "      <td>12.665149</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>0.855052</td>\n",
       "      <td>0.213650</td>\n",
       "      <td>tavares2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3341.584506</td>\n",
       "      <td>4984.396269</td>\n",
       "      <td>289.0</td>\n",
       "      <td>40259.0</td>\n",
       "      <td>27.691518</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>0.826173</td>\n",
       "      <td>0.149680</td>\n",
       "      <td>tavares2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1271.193815</td>\n",
       "      <td>1127.552996</td>\n",
       "      <td>243.0</td>\n",
       "      <td>9399.0</td>\n",
       "      <td>7.145720</td>\n",
       "      <td>771.0</td>\n",
       "      <td>1353.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0.865663</td>\n",
       "      <td>0.287849</td>\n",
       "      <td>tavares2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2420.559574</td>\n",
       "      <td>2655.438637</td>\n",
       "      <td>317.0</td>\n",
       "      <td>21727.0</td>\n",
       "      <td>14.640130</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>2556.0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>0.833769</td>\n",
       "      <td>0.326199</td>\n",
       "      <td>tavares2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1458.849035</td>\n",
       "      <td>823.192480</td>\n",
       "      <td>267.0</td>\n",
       "      <td>6268.0</td>\n",
       "      <td>4.555819</td>\n",
       "      <td>944.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>0.770567</td>\n",
       "      <td>0.160005</td>\n",
       "      <td>tavares2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rt                                                          \\\n",
       "                mean          std    min      max         se      q1      q3   \n",
       "subject                                                                        \n",
       "113      2189.337197  2153.038110  286.0  17284.0  12.665149  1144.0  2389.0   \n",
       "114      3341.584506  4984.396269  289.0  40259.0  27.691518  1380.0  3250.0   \n",
       "115      1271.193815  1127.552996  243.0   9399.0   7.145720   771.0  1353.0   \n",
       "116      2420.559574  2655.438637  317.0  21727.0  14.640130  1248.0  2556.0   \n",
       "117      1458.849035   823.192480  267.0   6268.0   4.555819   944.0  1716.0   \n",
       "\n",
       "                best_chosen gaze_influence      dataset  \n",
       "            iqr        mean                              \n",
       "subject                                                  \n",
       "113      1245.0    0.855052       0.213650  tavares2017  \n",
       "114      1870.0    0.826173       0.149680  tavares2017  \n",
       "115       582.0    0.865663       0.287849  tavares2017  \n",
       "116      1308.0    0.833769       0.326199  tavares2017  \n",
       "117       772.0    0.770567       0.160005  tavares2017  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_multiplicative_summary.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed effects analysis of prediction biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rt</th>\n",
       "      <th>best_chosen</th>\n",
       "      <th>gaze_influence</th>\n",
       "      <th>is_pred</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1704.177778</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>-0.020529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1728.489796</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.247233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4078.660000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1893.545455</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>-0.022031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1846.640000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.103622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_rt  best_chosen  gaze_influence  is_pred       dataset\n",
       "0  1704.177778     0.822222       -0.020529      0.0  krajbich2010\n",
       "1  1728.489796     0.673469        0.247233      0.0  krajbich2010\n",
       "2  4078.660000     0.840000        0.028877      0.0  krajbich2010\n",
       "3  1893.545455     0.704545       -0.022031      0.0  krajbich2010\n",
       "4  1846.640000     0.840000        0.103622      0.0  krajbich2010"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat data for mixed model\n",
    "mean_rt = np.concatenate([odd_summary['rt']['mean'].values,\n",
    "                          pred_multiplicative_summary['rt']['mean'].values],\n",
    "                         axis=0)\n",
    "best_chosen = np.concatenate([odd_summary['best_chosen']['mean'].values,\n",
    "                              pred_multiplicative_summary['best_chosen']['mean'].values],\n",
    "                             axis=0)\n",
    "gaze_influence = np.concatenate([odd_summary['gaze_influence'].values,\n",
    "                                 pred_multiplicative_summary['gaze_influence'].values],\n",
    "                                axis=0)\n",
    "\n",
    "is_pred = np.concatenate([np.zeros(len(odd_summary)),\n",
    "                          np.ones(len(pred_multiplicative_summary))],\n",
    "                         axis=0)\n",
    "dataset = np.concatenate([odd_summary['dataset'].values,\n",
    "                          pred_multiplicative_summary['dataset'].values],\n",
    "                         axis=0)\n",
    "\n",
    "df = pd.DataFrame(dict(mean_rt=mean_rt,\n",
    "                       best_chosen=best_chosen,\n",
    "                       gaze_influence=gaze_influence,\n",
    "                       is_pred=is_pred,\n",
    "                       dataset=dataset))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = -102.41:  46%|████▌     | 22940/50000 [00:18<00:21, 1248.43it/s] \n",
      "Convergence archived at 23000\n",
      "Interrupted at 22,999 [45%]: Average Loss = 1,903\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [gaze_influence_sd_interval__, is_pred|dataset_offset, is_pred|dataset_sd_log__, 1|dataset_offset, 1|dataset_sd_log__, is_pred, Intercept]\n",
      "100%|██████████| 20500/20500 [03:27<00:00, 98.96it/s]\n",
      "100%|██████████| 20500/20500 [03:24<00:00, 100.02it/s]\n",
      "There were 245 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 451 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hpd0.95_lower</th>\n",
       "      <th>hpd0.95_upper</th>\n",
       "      <th>effective_n</th>\n",
       "      <th>gelman_rubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[folke2016]</th>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>-5.896349e-02</td>\n",
       "      <td>0.082816</td>\n",
       "      <td>548</td>\n",
       "      <td>1.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2010]</th>\n",
       "      <td>-0.009886</td>\n",
       "      <td>0.036081</td>\n",
       "      <td>-8.436952e-02</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>429</td>\n",
       "      <td>1.004118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2011]</th>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.035602</td>\n",
       "      <td>-6.562848e-02</td>\n",
       "      <td>0.070636</td>\n",
       "      <td>396</td>\n",
       "      <td>1.003242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[tavares2017]</th>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.035546</td>\n",
       "      <td>-6.716548e-02</td>\n",
       "      <td>0.074427</td>\n",
       "      <td>454</td>\n",
       "      <td>1.002978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset_sd</th>\n",
       "      <td>0.035896</td>\n",
       "      <td>0.043408</td>\n",
       "      <td>5.817650e-07</td>\n",
       "      <td>0.112897</td>\n",
       "      <td>390</td>\n",
       "      <td>1.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaze_influence_sd</th>\n",
       "      <td>0.143388</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>1.340886e-01</td>\n",
       "      <td>0.152977</td>\n",
       "      <td>17016</td>\n",
       "      <td>1.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred</th>\n",
       "      <td>-0.022051</td>\n",
       "      <td>0.035455</td>\n",
       "      <td>-8.253339e-02</td>\n",
       "      <td>0.042121</td>\n",
       "      <td>431</td>\n",
       "      <td>1.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.240041</td>\n",
       "      <td>0.047946</td>\n",
       "      <td>1.449192e-01</td>\n",
       "      <td>0.340855</td>\n",
       "      <td>765</td>\n",
       "      <td>1.004340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[folke2016]</th>\n",
       "      <td>0.081390</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>-1.977554e-02</td>\n",
       "      <td>0.186141</td>\n",
       "      <td>813</td>\n",
       "      <td>1.004182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2010]</th>\n",
       "      <td>-0.039964</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>-1.455025e-01</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>855</td>\n",
       "      <td>1.003416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2011]</th>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.049217</td>\n",
       "      <td>-9.820974e-02</td>\n",
       "      <td>0.103785</td>\n",
       "      <td>825</td>\n",
       "      <td>1.004046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[tavares2017]</th>\n",
       "      <td>-0.034492</td>\n",
       "      <td>0.050139</td>\n",
       "      <td>-1.386139e-01</td>\n",
       "      <td>0.065620</td>\n",
       "      <td>850</td>\n",
       "      <td>1.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset_sd</th>\n",
       "      <td>0.080697</td>\n",
       "      <td>0.040012</td>\n",
       "      <td>2.181458e-02</td>\n",
       "      <td>0.165967</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.000586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean        sd  hpd0.95_lower  \\\n",
       "is_pred|dataset[folke2016]     0.005786  0.035830  -5.896349e-02   \n",
       "is_pred|dataset[krajbich2010] -0.009886  0.036081  -8.436952e-02   \n",
       "is_pred|dataset[krajbich2011] -0.000542  0.035602  -6.562848e-02   \n",
       "is_pred|dataset[tavares2017]  -0.000806  0.035546  -6.716548e-02   \n",
       "is_pred|dataset_sd             0.035896  0.043408   5.817650e-07   \n",
       "gaze_influence_sd              0.143388  0.005333   1.340886e-01   \n",
       "is_pred                       -0.022051  0.035455  -8.253339e-02   \n",
       "Intercept                      0.240041  0.047946   1.449192e-01   \n",
       "1|dataset[folke2016]           0.081390  0.051597  -1.977554e-02   \n",
       "1|dataset[krajbich2010]       -0.039964  0.049367  -1.455025e-01   \n",
       "1|dataset[krajbich2011]        0.003646  0.049217  -9.820974e-02   \n",
       "1|dataset[tavares2017]        -0.034492  0.050139  -1.386139e-01   \n",
       "1|dataset_sd                   0.080697  0.040012   2.181458e-02   \n",
       "\n",
       "                               hpd0.95_upper  effective_n  gelman_rubin  \n",
       "is_pred|dataset[folke2016]          0.082816          548      1.002607  \n",
       "is_pred|dataset[krajbich2010]       0.052604          429      1.004118  \n",
       "is_pred|dataset[krajbich2011]       0.070636          396      1.003242  \n",
       "is_pred|dataset[tavares2017]        0.074427          454      1.002978  \n",
       "is_pred|dataset_sd                  0.112897          390      1.001424  \n",
       "gaze_influence_sd                   0.152977        17016      1.000082  \n",
       "is_pred                             0.042121          431      1.003064  \n",
       "Intercept                           0.340855          765      1.004340  \n",
       "1|dataset[folke2016]                0.186141          813      1.004182  \n",
       "1|dataset[krajbich2010]             0.056396          855      1.003416  \n",
       "1|dataset[krajbich2011]             0.103785          825      1.004046  \n",
       "1|dataset[tavares2017]              0.065620          850      1.003859  \n",
       "1|dataset_sd                        0.165967         1623      1.000586  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(df)\n",
    "results_gaze_influence = model.fit('gaze_influence ~ is_pred',\n",
    "                                   random=['is_pred|dataset'],\n",
    "                                   categorical=['dataset'],\n",
    "                                   samples=n_samples)\n",
    "\n",
    "bias_analysis_glam_gaze_influence = results_gaze_influence.summary(ranefs=True)\n",
    "bias_analysis_glam_gaze_influence.to_csv(os.path.join('results', 'mixed_effects_models', '3_abs_fit_bias_glam_gaze.csv'))\n",
    "bias_analysis_glam_gaze_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 1,998.8: 100%|██████████| 50000/50000 [00:39<00:00, 1256.19it/s]\n",
      "Finished [100%]: Average Loss = 1,998.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mean_rt_sd_interval__, is_pred|dataset_offset, is_pred|dataset_sd_log__, 1|dataset_offset, 1|dataset_sd_log__, is_pred, Intercept]\n",
      "100%|██████████| 20500/20500 [11:09<00:00, 30.63it/s]\n",
      "100%|██████████| 20500/20500 [12:08<00:00, 28.15it/s]\n",
      "There were 165 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 249 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hpd0.95_lower</th>\n",
       "      <th>hpd0.95_upper</th>\n",
       "      <th>effective_n</th>\n",
       "      <th>gelman_rubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[folke2016]</th>\n",
       "      <td>6.183238</td>\n",
       "      <td>193.424643</td>\n",
       "      <td>-418.517774</td>\n",
       "      <td>439.787199</td>\n",
       "      <td>2793</td>\n",
       "      <td>1.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2010]</th>\n",
       "      <td>-13.927032</td>\n",
       "      <td>181.691662</td>\n",
       "      <td>-425.657753</td>\n",
       "      <td>376.940723</td>\n",
       "      <td>2220</td>\n",
       "      <td>1.001247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2011]</th>\n",
       "      <td>-15.680129</td>\n",
       "      <td>189.891561</td>\n",
       "      <td>-454.574960</td>\n",
       "      <td>390.925857</td>\n",
       "      <td>2408</td>\n",
       "      <td>1.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[tavares2017]</th>\n",
       "      <td>9.238693</td>\n",
       "      <td>194.331711</td>\n",
       "      <td>-414.882331</td>\n",
       "      <td>443.869557</td>\n",
       "      <td>2276</td>\n",
       "      <td>1.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset_sd</th>\n",
       "      <td>226.660761</td>\n",
       "      <td>251.766992</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>686.596580</td>\n",
       "      <td>1047</td>\n",
       "      <td>1.002964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred</th>\n",
       "      <td>-9.132202</td>\n",
       "      <td>183.321313</td>\n",
       "      <td>-409.726087</td>\n",
       "      <td>344.452495</td>\n",
       "      <td>1592</td>\n",
       "      <td>1.002040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>2944.900317</td>\n",
       "      <td>743.890997</td>\n",
       "      <td>1488.746634</td>\n",
       "      <td>4416.812658</td>\n",
       "      <td>1052</td>\n",
       "      <td>1.002927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[folke2016]</th>\n",
       "      <td>2370.965658</td>\n",
       "      <td>751.982456</td>\n",
       "      <td>948.822934</td>\n",
       "      <td>3931.385639</td>\n",
       "      <td>1118</td>\n",
       "      <td>1.002462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2010]</th>\n",
       "      <td>-781.187041</td>\n",
       "      <td>748.869686</td>\n",
       "      <td>-2221.514423</td>\n",
       "      <td>752.620702</td>\n",
       "      <td>1086</td>\n",
       "      <td>1.002634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2011]</th>\n",
       "      <td>-521.260399</td>\n",
       "      <td>750.008881</td>\n",
       "      <td>-2026.287790</td>\n",
       "      <td>944.050806</td>\n",
       "      <td>1107</td>\n",
       "      <td>1.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[tavares2017]</th>\n",
       "      <td>-1044.707300</td>\n",
       "      <td>753.842420</td>\n",
       "      <td>-2516.386525</td>\n",
       "      <td>457.643558</td>\n",
       "      <td>1111</td>\n",
       "      <td>1.002368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_rt_sd</th>\n",
       "      <td>1033.254267</td>\n",
       "      <td>48.512640</td>\n",
       "      <td>940.716954</td>\n",
       "      <td>1130.169352</td>\n",
       "      <td>40000</td>\n",
       "      <td>1.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset_sd</th>\n",
       "      <td>1605.862863</td>\n",
       "      <td>505.958319</td>\n",
       "      <td>775.372014</td>\n",
       "      <td>2607.922055</td>\n",
       "      <td>5296</td>\n",
       "      <td>1.000281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean          sd  hpd0.95_lower  \\\n",
       "is_pred|dataset[folke2016]        6.183238  193.424643    -418.517774   \n",
       "is_pred|dataset[krajbich2010]   -13.927032  181.691662    -425.657753   \n",
       "is_pred|dataset[krajbich2011]   -15.680129  189.891561    -454.574960   \n",
       "is_pred|dataset[tavares2017]      9.238693  194.331711    -414.882331   \n",
       "is_pred|dataset_sd              226.660761  251.766992       0.016741   \n",
       "is_pred                          -9.132202  183.321313    -409.726087   \n",
       "Intercept                      2944.900317  743.890997    1488.746634   \n",
       "1|dataset[folke2016]           2370.965658  751.982456     948.822934   \n",
       "1|dataset[krajbich2010]        -781.187041  748.869686   -2221.514423   \n",
       "1|dataset[krajbich2011]        -521.260399  750.008881   -2026.287790   \n",
       "1|dataset[tavares2017]        -1044.707300  753.842420   -2516.386525   \n",
       "mean_rt_sd                     1033.254267   48.512640     940.716954   \n",
       "1|dataset_sd                   1605.862863  505.958319     775.372014   \n",
       "\n",
       "                               hpd0.95_upper  effective_n  gelman_rubin  \n",
       "is_pred|dataset[folke2016]        439.787199         2793      1.000765  \n",
       "is_pred|dataset[krajbich2010]     376.940723         2220      1.001247  \n",
       "is_pred|dataset[krajbich2011]     390.925857         2408      1.000426  \n",
       "is_pred|dataset[tavares2017]      443.869557         2276      1.000827  \n",
       "is_pred|dataset_sd                686.596580         1047      1.002964  \n",
       "is_pred                           344.452495         1592      1.002040  \n",
       "Intercept                        4416.812658         1052      1.002927  \n",
       "1|dataset[folke2016]             3931.385639         1118      1.002462  \n",
       "1|dataset[krajbich2010]           752.620702         1086      1.002634  \n",
       "1|dataset[krajbich2011]           944.050806         1107      1.002577  \n",
       "1|dataset[tavares2017]            457.643558         1111      1.002368  \n",
       "mean_rt_sd                       1130.169352        40000      1.000045  \n",
       "1|dataset_sd                     2607.922055         5296      1.000281  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mean_rt = model.fit('mean_rt ~ is_pred',\n",
    "                            random=['is_pred|dataset'],\n",
    "                            categorical=['dataset'],\n",
    "                            samples=n_samples)\n",
    "\n",
    "bias_analysis_glam_mean_rt = results_mean_rt.summary(ranefs=True)\n",
    "bias_analysis_glam_mean_rt.to_csv(os.path.join('results', 'mixed_effects_models', '3_abs_fit_bias_glam_rt.csv'))\n",
    "bias_analysis_glam_mean_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = -189.34:  45%|████▌     | 22603/50000 [00:18<00:22, 1221.66it/s]\n",
      "Convergence archived at 22700\n",
      "Interrupted at 22,699 [45%]: Average Loss = 3,005.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [best_chosen_sd_interval__, is_pred|dataset_offset, is_pred|dataset_sd_log__, 1|dataset_offset, 1|dataset_sd_log__, is_pred, Intercept]\n",
      "100%|██████████| 20500/20500 [04:59<00:00, 68.48it/s]\n",
      "100%|██████████| 20500/20500 [04:59<00:00, 68.51it/s]\n",
      "There were 18 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 38 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hpd0.95_lower</th>\n",
       "      <th>hpd0.95_upper</th>\n",
       "      <th>effective_n</th>\n",
       "      <th>gelman_rubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[folke2016]</th>\n",
       "      <td>-0.006850</td>\n",
       "      <td>0.025211</td>\n",
       "      <td>-6.294348e-02</td>\n",
       "      <td>0.042713</td>\n",
       "      <td>14227</td>\n",
       "      <td>1.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2010]</th>\n",
       "      <td>0.010806</td>\n",
       "      <td>0.025016</td>\n",
       "      <td>-3.388074e-02</td>\n",
       "      <td>0.068218</td>\n",
       "      <td>12820</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2011]</th>\n",
       "      <td>-0.008073</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>-6.704170e-02</td>\n",
       "      <td>0.036807</td>\n",
       "      <td>13663</td>\n",
       "      <td>1.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[tavares2017]</th>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.024995</td>\n",
       "      <td>-4.385866e-02</td>\n",
       "      <td>0.061252</td>\n",
       "      <td>13825</td>\n",
       "      <td>1.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset_sd</th>\n",
       "      <td>0.029641</td>\n",
       "      <td>0.031191</td>\n",
       "      <td>6.969388e-07</td>\n",
       "      <td>0.088930</td>\n",
       "      <td>8430</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred</th>\n",
       "      <td>-0.022139</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>-7.026238e-02</td>\n",
       "      <td>0.023049</td>\n",
       "      <td>12781</td>\n",
       "      <td>1.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.767203</td>\n",
       "      <td>0.051055</td>\n",
       "      <td>6.602676e-01</td>\n",
       "      <td>0.868185</td>\n",
       "      <td>7143</td>\n",
       "      <td>1.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[folke2016]</th>\n",
       "      <td>-0.110091</td>\n",
       "      <td>0.052479</td>\n",
       "      <td>-2.205632e-01</td>\n",
       "      <td>-0.007200</td>\n",
       "      <td>7728</td>\n",
       "      <td>1.000155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2010]</th>\n",
       "      <td>0.050345</td>\n",
       "      <td>0.051821</td>\n",
       "      <td>-5.546481e-02</td>\n",
       "      <td>0.154463</td>\n",
       "      <td>6947</td>\n",
       "      <td>1.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2011]</th>\n",
       "      <td>-0.031545</td>\n",
       "      <td>0.052142</td>\n",
       "      <td>-1.387941e-01</td>\n",
       "      <td>0.072376</td>\n",
       "      <td>7432</td>\n",
       "      <td>1.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[tavares2017]</th>\n",
       "      <td>0.094510</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>-1.174856e-02</td>\n",
       "      <td>0.200963</td>\n",
       "      <td>7580</td>\n",
       "      <td>1.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_chosen_sd</th>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>8.746727e-02</td>\n",
       "      <td>0.104966</td>\n",
       "      <td>33190</td>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset_sd</th>\n",
       "      <td>0.101423</td>\n",
       "      <td>0.036252</td>\n",
       "      <td>4.363020e-02</td>\n",
       "      <td>0.173076</td>\n",
       "      <td>10656</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean        sd  hpd0.95_lower  \\\n",
       "is_pred|dataset[folke2016]    -0.006850  0.025211  -6.294348e-02   \n",
       "is_pred|dataset[krajbich2010]  0.010806  0.025016  -3.388074e-02   \n",
       "is_pred|dataset[krajbich2011] -0.008073  0.025001  -6.704170e-02   \n",
       "is_pred|dataset[tavares2017]   0.003912  0.024995  -4.385866e-02   \n",
       "is_pred|dataset_sd             0.029641  0.031191   6.969388e-07   \n",
       "is_pred                       -0.022139  0.023374  -7.026238e-02   \n",
       "Intercept                      0.767203  0.051055   6.602676e-01   \n",
       "1|dataset[folke2016]          -0.110091  0.052479  -2.205632e-01   \n",
       "1|dataset[krajbich2010]        0.050345  0.051821  -5.546481e-02   \n",
       "1|dataset[krajbich2011]       -0.031545  0.052142  -1.387941e-01   \n",
       "1|dataset[tavares2017]         0.094510  0.052351  -1.174856e-02   \n",
       "best_chosen_sd                 0.096000  0.004509   8.746727e-02   \n",
       "1|dataset_sd                   0.101423  0.036252   4.363020e-02   \n",
       "\n",
       "                               hpd0.95_upper  effective_n  gelman_rubin  \n",
       "is_pred|dataset[folke2016]          0.042713        14227      1.000141  \n",
       "is_pred|dataset[krajbich2010]       0.068218        12820      0.999994  \n",
       "is_pred|dataset[krajbich2011]       0.036807        13663      1.000039  \n",
       "is_pred|dataset[tavares2017]        0.061252        13825      1.000016  \n",
       "is_pred|dataset_sd                  0.088930         8430      0.999975  \n",
       "is_pred                             0.023049        12781      1.000022  \n",
       "Intercept                           0.868185         7143      1.000083  \n",
       "1|dataset[folke2016]               -0.007200         7728      1.000155  \n",
       "1|dataset[krajbich2010]             0.154463         6947      1.000062  \n",
       "1|dataset[krajbich2011]             0.072376         7432      1.000085  \n",
       "1|dataset[tavares2017]              0.200963         7580      1.000098  \n",
       "best_chosen_sd                      0.104966        33190      0.999979  \n",
       "1|dataset_sd                        0.173076        10656      0.999986  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_best_chosen = model.fit('best_chosen ~ is_pred',\n",
    "                                random=['is_pred|dataset'],\n",
    "                                categorical=['dataset'],\n",
    "                                samples=n_samples)\n",
    "\n",
    "bias_analysis_glam_best_chosen = results_best_chosen.summary(ranefs=True)\n",
    "bias_analysis_glam_best_chosen.to_csv(os.path.join('results', 'mixed_effects_models', '3_abs_fit_bias_glam_best_chosen.csv'))\n",
    "bias_analysis_glam_best_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rt</th>\n",
       "      <th>best_chosen</th>\n",
       "      <th>gaze_influence</th>\n",
       "      <th>is_pred</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1704.177778</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>-0.020529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1728.489796</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.247233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4078.660000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1893.545455</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>-0.022031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1846.640000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.103622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>krajbich2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_rt  best_chosen  gaze_influence  is_pred       dataset\n",
       "0  1704.177778     0.822222       -0.020529      0.0  krajbich2010\n",
       "1  1728.489796     0.673469        0.247233      0.0  krajbich2010\n",
       "2  4078.660000     0.840000        0.028877      0.0  krajbich2010\n",
       "3  1893.545455     0.704545       -0.022031      0.0  krajbich2010\n",
       "4  1846.640000     0.840000        0.103622      0.0  krajbich2010"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for mixed model\n",
    "mean_rt = np.concatenate([odd_summary['rt']['mean'].values,\n",
    "                          pred_nobias_summary['rt']['mean'].values],\n",
    "                         axis=0)\n",
    "best_chosen = np.concatenate([odd_summary['best_chosen']['mean'].values,\n",
    "                              pred_nobias_summary['best_chosen']['mean'].values],\n",
    "                             axis=0)\n",
    "gaze_influence = np.concatenate([odd_summary['gaze_influence'].values,\n",
    "                                 pred_nobias_summary['gaze_influence'].values],\n",
    "                                axis=0)\n",
    "\n",
    "is_pred = np.concatenate([np.zeros(len(odd_summary)),\n",
    "                          np.ones(len(pred_nobias_summary))],\n",
    "                         axis=0)\n",
    "dataset = np.concatenate([odd_summary['dataset'].values,\n",
    "                          pred_nobias_summary['dataset'].values],\n",
    "                         axis=0)\n",
    "\n",
    "df = pd.DataFrame(dict(mean_rt=mean_rt,\n",
    "                       best_chosen=best_chosen,\n",
    "                       gaze_influence=gaze_influence,\n",
    "                       is_pred=is_pred,\n",
    "                       dataset=dataset))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = -167.28:  51%|█████     | 25351/50000 [00:19<00:19, 1271.14it/s]\n",
      "Convergence archived at 25400\n",
      "Interrupted at 25,399 [50%]: Average Loss = 1,380.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [gaze_influence_sd_interval__, is_pred|dataset_offset, is_pred|dataset_sd_log__, 1|dataset_offset, 1|dataset_sd_log__, is_pred, Intercept]\n",
      "100%|██████████| 20500/20500 [05:03<00:00, 67.54it/s]\n",
      "100%|██████████| 20500/20500 [04:12<00:00, 81.16it/s]\n",
      "There were 23 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 196 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hpd0.95_lower</th>\n",
       "      <th>hpd0.95_upper</th>\n",
       "      <th>effective_n</th>\n",
       "      <th>gelman_rubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[folke2016]</th>\n",
       "      <td>-0.064004</td>\n",
       "      <td>0.052485</td>\n",
       "      <td>-0.175414</td>\n",
       "      <td>0.022771</td>\n",
       "      <td>1838</td>\n",
       "      <td>1.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2010]</th>\n",
       "      <td>0.015505</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>-0.078539</td>\n",
       "      <td>0.105360</td>\n",
       "      <td>2085</td>\n",
       "      <td>1.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2011]</th>\n",
       "      <td>-0.010303</td>\n",
       "      <td>0.043774</td>\n",
       "      <td>-0.109497</td>\n",
       "      <td>0.075273</td>\n",
       "      <td>1854</td>\n",
       "      <td>1.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[tavares2017]</th>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.043824</td>\n",
       "      <td>-0.075261</td>\n",
       "      <td>0.111455</td>\n",
       "      <td>2190</td>\n",
       "      <td>1.000292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset_sd</th>\n",
       "      <td>0.068428</td>\n",
       "      <td>0.048503</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.164987</td>\n",
       "      <td>2123</td>\n",
       "      <td>1.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaze_influence_sd</th>\n",
       "      <td>0.108833</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.098903</td>\n",
       "      <td>0.119399</td>\n",
       "      <td>40000</td>\n",
       "      <td>1.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred</th>\n",
       "      <td>-0.227179</td>\n",
       "      <td>0.041045</td>\n",
       "      <td>-0.308115</td>\n",
       "      <td>-0.131912</td>\n",
       "      <td>1640</td>\n",
       "      <td>1.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.236765</td>\n",
       "      <td>0.036684</td>\n",
       "      <td>0.156990</td>\n",
       "      <td>0.311178</td>\n",
       "      <td>1972</td>\n",
       "      <td>1.001390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[folke2016]</th>\n",
       "      <td>0.069280</td>\n",
       "      <td>0.041886</td>\n",
       "      <td>-0.005757</td>\n",
       "      <td>0.161977</td>\n",
       "      <td>3436</td>\n",
       "      <td>1.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2010]</th>\n",
       "      <td>-0.029083</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>-0.109351</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>2128</td>\n",
       "      <td>1.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2011]</th>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.038552</td>\n",
       "      <td>-0.073522</td>\n",
       "      <td>0.087757</td>\n",
       "      <td>2283</td>\n",
       "      <td>1.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[tavares2017]</th>\n",
       "      <td>-0.029795</td>\n",
       "      <td>0.039038</td>\n",
       "      <td>-0.109882</td>\n",
       "      <td>0.050387</td>\n",
       "      <td>2330</td>\n",
       "      <td>1.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset_sd</th>\n",
       "      <td>0.066907</td>\n",
       "      <td>0.034044</td>\n",
       "      <td>0.013615</td>\n",
       "      <td>0.137498</td>\n",
       "      <td>6478</td>\n",
       "      <td>1.000045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean        sd  hpd0.95_lower  \\\n",
       "is_pred|dataset[folke2016]    -0.064004  0.052485      -0.175414   \n",
       "is_pred|dataset[krajbich2010]  0.015505  0.042666      -0.078539   \n",
       "is_pred|dataset[krajbich2011] -0.010303  0.043774      -0.109497   \n",
       "is_pred|dataset[tavares2017]   0.017728  0.043824      -0.075261   \n",
       "is_pred|dataset_sd             0.068428  0.048503       0.000006   \n",
       "gaze_influence_sd              0.108833  0.005229       0.098903   \n",
       "is_pred                       -0.227179  0.041045      -0.308115   \n",
       "Intercept                      0.236765  0.036684       0.156990   \n",
       "1|dataset[folke2016]           0.069280  0.041886      -0.005757   \n",
       "1|dataset[krajbich2010]       -0.029083  0.038281      -0.109351   \n",
       "1|dataset[krajbich2011]        0.004569  0.038552      -0.073522   \n",
       "1|dataset[tavares2017]        -0.029795  0.039038      -0.109882   \n",
       "1|dataset_sd                   0.066907  0.034044       0.013615   \n",
       "\n",
       "                               hpd0.95_upper  effective_n  gelman_rubin  \n",
       "is_pred|dataset[folke2016]          0.022771         1838      1.000588  \n",
       "is_pred|dataset[krajbich2010]       0.105360         2085      1.000359  \n",
       "is_pred|dataset[krajbich2011]       0.075273         1854      1.000669  \n",
       "is_pred|dataset[tavares2017]        0.111455         2190      1.000292  \n",
       "is_pred|dataset_sd                  0.164987         2123      1.000267  \n",
       "gaze_influence_sd                   0.119399        40000      1.000112  \n",
       "is_pred                            -0.131912         1640      1.000545  \n",
       "Intercept                           0.311178         1972      1.001390  \n",
       "1|dataset[folke2016]                0.161977         3436      1.000709  \n",
       "1|dataset[krajbich2010]             0.049900         2128      1.001224  \n",
       "1|dataset[krajbich2011]             0.087757         2283      1.001138  \n",
       "1|dataset[tavares2017]              0.050387         2330      1.001483  \n",
       "1|dataset_sd                        0.137498         6478      1.000045  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(df)\n",
    "results_gaze_influence = model.fit('gaze_influence ~ is_pred',\n",
    "                                   random=['is_pred|dataset'],\n",
    "                                   categorical=['dataset'],\n",
    "                                   samples=n_samples)\n",
    "\n",
    "bias_analysis_nobias_gaze_influence = results_gaze_influence.summary(ranefs=True)\n",
    "bias_analysis_nobias_gaze_influence.to_csv(os.path.join('results', 'mixed_effects_models', '3_abs_fit_bias_nobias_gaze.csv'))\n",
    "bias_analysis_nobias_gaze_influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 2,004.7: 100%|██████████| 50000/50000 [00:38<00:00, 1282.19it/s]\n",
      "Finished [100%]: Average Loss = 2,004.7\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [mean_rt_sd_interval__, is_pred|dataset_offset, is_pred|dataset_sd_log__, 1|dataset_offset, 1|dataset_sd_log__, is_pred, Intercept]\n",
      "100%|██████████| 20500/20500 [14:15<00:00, 23.95it/s]\n",
      "100%|██████████| 20500/20500 [15:17<00:00, 22.34it/s]\n",
      "There were 125 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 223 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 10% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hpd0.95_lower</th>\n",
       "      <th>hpd0.95_upper</th>\n",
       "      <th>effective_n</th>\n",
       "      <th>gelman_rubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[folke2016]</th>\n",
       "      <td>-2.526226</td>\n",
       "      <td>195.730639</td>\n",
       "      <td>-442.559707</td>\n",
       "      <td>419.515893</td>\n",
       "      <td>5191</td>\n",
       "      <td>1.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2010]</th>\n",
       "      <td>-17.880493</td>\n",
       "      <td>184.558756</td>\n",
       "      <td>-431.111345</td>\n",
       "      <td>369.979637</td>\n",
       "      <td>3924</td>\n",
       "      <td>1.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2011]</th>\n",
       "      <td>5.378380</td>\n",
       "      <td>189.572513</td>\n",
       "      <td>-407.977578</td>\n",
       "      <td>422.470261</td>\n",
       "      <td>4321</td>\n",
       "      <td>1.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[tavares2017]</th>\n",
       "      <td>5.896717</td>\n",
       "      <td>193.936155</td>\n",
       "      <td>-413.332875</td>\n",
       "      <td>443.886545</td>\n",
       "      <td>4985</td>\n",
       "      <td>1.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset_sd</th>\n",
       "      <td>227.115535</td>\n",
       "      <td>246.036493</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>691.711755</td>\n",
       "      <td>2288</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred</th>\n",
       "      <td>14.652198</td>\n",
       "      <td>185.818392</td>\n",
       "      <td>-354.925326</td>\n",
       "      <td>412.874884</td>\n",
       "      <td>2788</td>\n",
       "      <td>1.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>2930.310779</td>\n",
       "      <td>795.489915</td>\n",
       "      <td>1289.818888</td>\n",
       "      <td>4439.705363</td>\n",
       "      <td>923</td>\n",
       "      <td>1.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[folke2016]</th>\n",
       "      <td>2374.522983</td>\n",
       "      <td>804.441179</td>\n",
       "      <td>828.028235</td>\n",
       "      <td>4005.160960</td>\n",
       "      <td>966</td>\n",
       "      <td>1.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2010]</th>\n",
       "      <td>-771.767522</td>\n",
       "      <td>800.579567</td>\n",
       "      <td>-2365.051578</td>\n",
       "      <td>796.446894</td>\n",
       "      <td>948</td>\n",
       "      <td>1.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2011]</th>\n",
       "      <td>-487.608329</td>\n",
       "      <td>802.376406</td>\n",
       "      <td>-2062.665692</td>\n",
       "      <td>1115.052138</td>\n",
       "      <td>948</td>\n",
       "      <td>1.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[tavares2017]</th>\n",
       "      <td>-1032.601397</td>\n",
       "      <td>803.738353</td>\n",
       "      <td>-2579.287276</td>\n",
       "      <td>612.248273</td>\n",
       "      <td>962</td>\n",
       "      <td>1.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_rt_sd</th>\n",
       "      <td>1057.685253</td>\n",
       "      <td>50.216135</td>\n",
       "      <td>959.967093</td>\n",
       "      <td>1155.933592</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset_sd</th>\n",
       "      <td>1623.546398</td>\n",
       "      <td>517.883354</td>\n",
       "      <td>782.440179</td>\n",
       "      <td>2679.704160</td>\n",
       "      <td>3999</td>\n",
       "      <td>1.000089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      mean          sd  hpd0.95_lower  \\\n",
       "is_pred|dataset[folke2016]       -2.526226  195.730639    -442.559707   \n",
       "is_pred|dataset[krajbich2010]   -17.880493  184.558756    -431.111345   \n",
       "is_pred|dataset[krajbich2011]     5.378380  189.572513    -407.977578   \n",
       "is_pred|dataset[tavares2017]      5.896717  193.936155    -413.332875   \n",
       "is_pred|dataset_sd              227.115535  246.036493       0.000107   \n",
       "is_pred                          14.652198  185.818392    -354.925326   \n",
       "Intercept                      2930.310779  795.489915    1289.818888   \n",
       "1|dataset[folke2016]           2374.522983  804.441179     828.028235   \n",
       "1|dataset[krajbich2010]        -771.767522  800.579567   -2365.051578   \n",
       "1|dataset[krajbich2011]        -487.608329  802.376406   -2062.665692   \n",
       "1|dataset[tavares2017]        -1032.601397  803.738353   -2579.287276   \n",
       "mean_rt_sd                     1057.685253   50.216135     959.967093   \n",
       "1|dataset_sd                   1623.546398  517.883354     782.440179   \n",
       "\n",
       "                               hpd0.95_upper  effective_n  gelman_rubin  \n",
       "is_pred|dataset[folke2016]        419.515893         5191      1.000126  \n",
       "is_pred|dataset[krajbich2010]     369.979637         3924      1.000357  \n",
       "is_pred|dataset[krajbich2011]     422.470261         4321      1.000615  \n",
       "is_pred|dataset[tavares2017]      443.886545         4985      1.000215  \n",
       "is_pred|dataset_sd                691.711755         2288      0.999977  \n",
       "is_pred                           412.874884         2788      1.001059  \n",
       "Intercept                        4439.705363          923      1.000255  \n",
       "1|dataset[folke2016]             4005.160960          966      1.000341  \n",
       "1|dataset[krajbich2010]           796.446894          948      1.000307  \n",
       "1|dataset[krajbich2011]          1115.052138          948      1.000252  \n",
       "1|dataset[tavares2017]            612.248273          962      1.000242  \n",
       "mean_rt_sd                       1155.933592        40000      0.999999  \n",
       "1|dataset_sd                     2679.704160         3999      1.000089  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_mean_rt = model.fit('mean_rt ~ is_pred',\n",
    "                            random=['is_pred|dataset'],\n",
    "                            categorical=['dataset'],\n",
    "                            samples=n_samples)\n",
    "\n",
    "bias_analysis_nobias_mean_rt = results_mean_rt.summary(ranefs=True)\n",
    "bias_analysis_nobias_mean_rt.to_csv(os.path.join('results', 'mixed_effects_models', '3_abs_fit_bias_nobias_rt.csv'))\n",
    "bias_analysis_nobias_mean_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4384: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4385: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = -207.03:  50%|████▉     | 24812/50000 [00:19<00:20, 1257.76it/s] \n",
      "Convergence archived at 24900\n",
      "Interrupted at 24,899 [49%]: Average Loss = 2,736.6\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [best_chosen_sd_interval__, is_pred|dataset_offset, is_pred|dataset_sd_log__, 1|dataset_offset, 1|dataset_sd_log__, is_pred, Intercept]\n",
      "100%|██████████| 20500/20500 [06:04<00:00, 56.31it/s]\n",
      "100%|██████████| 20500/20500 [06:05<00:00, 56.08it/s]\n",
      "There were 16 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 35 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hpd0.95_lower</th>\n",
       "      <th>hpd0.95_upper</th>\n",
       "      <th>effective_n</th>\n",
       "      <th>gelman_rubin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[folke2016]</th>\n",
       "      <td>-0.009518</td>\n",
       "      <td>0.024767</td>\n",
       "      <td>-0.067449</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>10982</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2010]</th>\n",
       "      <td>0.014496</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>0.072145</td>\n",
       "      <td>7709</td>\n",
       "      <td>0.999977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[krajbich2011]</th>\n",
       "      <td>-0.003072</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>-0.054723</td>\n",
       "      <td>0.046599</td>\n",
       "      <td>8274</td>\n",
       "      <td>1.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset[tavares2017]</th>\n",
       "      <td>-0.001081</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>-0.052884</td>\n",
       "      <td>0.051231</td>\n",
       "      <td>8060</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred|dataset_sd</th>\n",
       "      <td>0.029804</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.088121</td>\n",
       "      <td>7866</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pred</th>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>-0.044332</td>\n",
       "      <td>0.048286</td>\n",
       "      <td>7507</td>\n",
       "      <td>0.999988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>0.769141</td>\n",
       "      <td>0.049428</td>\n",
       "      <td>0.669974</td>\n",
       "      <td>0.869689</td>\n",
       "      <td>7060</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[folke2016]</th>\n",
       "      <td>-0.113719</td>\n",
       "      <td>0.050585</td>\n",
       "      <td>-0.214910</td>\n",
       "      <td>-0.011406</td>\n",
       "      <td>7618</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2010]</th>\n",
       "      <td>0.049531</td>\n",
       "      <td>0.050381</td>\n",
       "      <td>-0.050653</td>\n",
       "      <td>0.152601</td>\n",
       "      <td>7309</td>\n",
       "      <td>0.999980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[krajbich2011]</th>\n",
       "      <td>-0.030279</td>\n",
       "      <td>0.050391</td>\n",
       "      <td>-0.132406</td>\n",
       "      <td>0.071070</td>\n",
       "      <td>7459</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset[tavares2017]</th>\n",
       "      <td>0.089115</td>\n",
       "      <td>0.050368</td>\n",
       "      <td>-0.009148</td>\n",
       "      <td>0.192995</td>\n",
       "      <td>7568</td>\n",
       "      <td>0.999986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_chosen_sd</th>\n",
       "      <td>0.089742</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.081760</td>\n",
       "      <td>0.098106</td>\n",
       "      <td>34822</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1|dataset_sd</th>\n",
       "      <td>0.099323</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>0.043781</td>\n",
       "      <td>0.168421</td>\n",
       "      <td>13472</td>\n",
       "      <td>1.000056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean        sd  hpd0.95_lower  \\\n",
       "is_pred|dataset[folke2016]    -0.009518  0.024767      -0.067449   \n",
       "is_pred|dataset[krajbich2010]  0.014496  0.025427      -0.030271   \n",
       "is_pred|dataset[krajbich2011] -0.003072  0.023852      -0.054723   \n",
       "is_pred|dataset[tavares2017]  -0.001081  0.024223      -0.052884   \n",
       "is_pred|dataset_sd             0.029804  0.029438       0.000001   \n",
       "is_pred                        0.001294  0.022764      -0.044332   \n",
       "Intercept                      0.769141  0.049428       0.669974   \n",
       "1|dataset[folke2016]          -0.113719  0.050585      -0.214910   \n",
       "1|dataset[krajbich2010]        0.049531  0.050381      -0.050653   \n",
       "1|dataset[krajbich2011]       -0.030279  0.050391      -0.132406   \n",
       "1|dataset[tavares2017]         0.089115  0.050368      -0.009148   \n",
       "best_chosen_sd                 0.089742  0.004200       0.081760   \n",
       "1|dataset_sd                   0.099323  0.034384       0.043781   \n",
       "\n",
       "                               hpd0.95_upper  effective_n  gelman_rubin  \n",
       "is_pred|dataset[folke2016]          0.034684        10982      0.999993  \n",
       "is_pred|dataset[krajbich2010]       0.072145         7709      0.999977  \n",
       "is_pred|dataset[krajbich2011]       0.046599         8274      1.000024  \n",
       "is_pred|dataset[tavares2017]        0.051231         8060      0.999978  \n",
       "is_pred|dataset_sd                  0.088121         7866      0.999981  \n",
       "is_pred                             0.048286         7507      0.999988  \n",
       "Intercept                           0.869689         7060      0.999981  \n",
       "1|dataset[folke2016]               -0.011406         7618      0.999978  \n",
       "1|dataset[krajbich2010]             0.152601         7309      0.999980  \n",
       "1|dataset[krajbich2011]             0.071070         7459      1.000000  \n",
       "1|dataset[tavares2017]              0.192995         7568      0.999986  \n",
       "best_chosen_sd                      0.098106        34822      0.999975  \n",
       "1|dataset_sd                        0.168421        13472      1.000056  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_best_chosen = model.fit('best_chosen ~ is_pred',\n",
    "                                random=['is_pred|dataset'],\n",
    "                                categorical=['dataset'],\n",
    "                                samples=n_samples)\n",
    "\n",
    "bias_analysis_nobias_best_chosen = results_best_chosen.summary(ranefs=True)\n",
    "bias_analysis_nobias_best_chosen.to_csv(os.path.join('results', 'mixed_effects_models', '3_abs_fit_bias_nobias_best_chosen.csv'))\n",
    "bias_analysis_nobias_best_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_5(observed, multiplicative, nobias,\n",
    "             figsize=(7.5, 4.5), colors=None, fontsize=8, alpha=1.0):\n",
    "\n",
    "    datasets = ['krajbich2010', 'krajbich2011', 'folke2016', 'tavares2017']\n",
    "    \n",
    "    if colors is None:\n",
    "        colors = np.array(['C{}'.format(i)\n",
    "                           for i in range(observed['dataset'].unique().size)])\n",
    "    color_idx = pd.Categorical(observed['dataset'], categories=datasets, ordered=True).codes.astype(int)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 3, figsize=figsize, sharex='col', sharey='col')\n",
    "    \n",
    "    for m, model in enumerate([multiplicative, nobias]):\n",
    "\n",
    "        # a) Mean RT\n",
    "        axs[m, 0].scatter(observed['rt']['mean'],\n",
    "                          model['rt']['mean'],\n",
    "                          color=colors[color_idx],\n",
    "                          marker='+',\n",
    "                          alpha=alpha)\n",
    "        axs[m, 0].set_xticks(np.arange(0, 10000, 2000))\n",
    "        axs[m, 0].set_yticks(np.arange(0, 10000, 2000))\n",
    "        axs[m, 0].set_xlim(0, 9000)\n",
    "        axs[m, 0].set_ylim(0, 9000)\n",
    "\n",
    "        \n",
    "        # b) P(choose best)\n",
    "        axs[m, 1].scatter(observed['best_chosen']['mean'],\n",
    "                          model['best_chosen']['mean'],\n",
    "                          color=colors[color_idx],\n",
    "                          marker='+',\n",
    "                          alpha=alpha)\n",
    "        axs[m, 1].set_xticks(np.arange(0.4, 1.1, 0.2))\n",
    "        axs[m, 1].set_yticks(np.arange(0.4, 1.1, 0.2))\n",
    "        axs[m, 1].set_xlim(0.3, 1.0)\n",
    "        axs[m, 1].set_ylim(0.3, 1.0)\n",
    "\n",
    "\n",
    "    \n",
    "        # c) Gaze Influence\n",
    "        axs[m, 2].scatter(observed['gaze_influence'],\n",
    "                          model['gaze_influence'],\n",
    "                          color=colors[color_idx],\n",
    "                          marker='+',\n",
    "                          alpha=alpha)\n",
    "        axs[m, 2].set_xticks(np.arange(-0.2, 1.1, 0.2))\n",
    "        axs[m, 2].set_yticks(np.arange(-0.2, 1.1, 0.2))\n",
    "        axs[m, 2].set_xlim(-0.25, 0.85)\n",
    "        axs[m, 2].set_ylim(-0.25, 0.85)\n",
    "\n",
    "\n",
    "\n",
    "    axs[0, 0].set_ylabel('GLAM\\n\\nPredicted', fontsize=fontsize)\n",
    "    axs[1, 0].set_ylabel('No-Bias\\n\\nPredicted', fontsize=fontsize)\n",
    "\n",
    "    axs[0, 0].set_title('Mean RT (ms)', fontsize=fontsize)\n",
    "    axs[0, 1].set_title('P(choose best)', fontsize=fontsize)\n",
    "    axs[0, 2].set_title('Gaze influence\\non P(choice | value)', fontsize=fontsize)\n",
    "     \n",
    "    axs[1, 0].set_xlabel('Observed', fontsize=fontsize)\n",
    "    axs[1, 1].set_xlabel('Observed', fontsize=fontsize)\n",
    "    axs[1, 2].set_xlabel('Observed', fontsize=fontsize)\n",
    "    \n",
    "    patches = [mpatches.Rectangle((0, 0), 0.5, 1, fc=\"C{}\".format(i))\n",
    "               for i in range(len(datasets))]\n",
    "\n",
    "    axs[0, 0].legend(patches,\n",
    "                     ['Krajbich 2010', 'Krajbich 2011', 'Folke 2016', 'Tavares 2017'],\n",
    "                     loc='upper left',\n",
    "                     handlelength=1, handleheight=1,\n",
    "                     fontsize=6,\n",
    "                     frameon=False)\n",
    "\n",
    "    # Labels\n",
    "    for label, ax in zip(list('abcdef'), axs.ravel()):\n",
    "        ax.text(-0.2, 1.2, label, transform=ax.transAxes,\n",
    "                fontsize=12, fontweight='bold', va='top')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        # Font sizes\n",
    "        ax.tick_params(axis='both', labelsize=8)\n",
    "\n",
    "        # Plot diagonal\n",
    "        ax.plot(ax.get_xlim(), ax.get_xlim(), linewidth=1, color='black', alpha=1.0, zorder=-1)\n",
    "        \n",
    "    \n",
    "    fig.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x324 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure_5(odd_summary, pred_multiplicative_summary, pred_nobias_summary, alpha=1);\n",
    "plt.savefig('results/figures/figure_5_absolute_model_fit.png', dpi=330, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
